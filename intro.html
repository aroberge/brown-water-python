
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>What is tokenization? &#8212; Brown Water Python  documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript" src="_static/documentation_options.js"></script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="tokenize vs. alternatives" href="alternatives.html" />
    <link rel="prev" title="Brown Water Python" href="index.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="what-is-tokenization">
<h1>What is tokenization?<a class="headerlink" href="#what-is-tokenization" title="Permalink to this headline">Â¶</a></h1>
<p>In the field of parsing, <a class="reference external" href="https://en.wikipedia.org/wiki/Lexical_analysis"><em>tokenizer</em></a>, also called a <em>lexer</em>, is a program
that takes a string of characters and splits it into tokens. A token is a
substring that has semantic meaning in the grammar of the language.</p>
<p>An example should clarify things. Consider the string of Python code, <code class="docutils literal notranslate"><span class="pre">(&quot;a&quot;)</span> <span class="pre">+</span>
<span class="pre">True</span> <span class="pre">-</span></code>.</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">tokenize</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">io</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">string</span> <span class="o">=</span> <span class="s1">&#39;(&quot;a&quot;) + True -&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokenize</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">readline</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">print</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
<span class="go">TokenInfo(type=59 (ENCODING), string=&#39;utf-8&#39;, start=(0, 0), end=(0, 0), line=&#39;&#39;)</span>
<span class="go">TokenInfo(type=53 (OP), string=&#39;(&#39;, start=(1, 0), end=(1, 1), line=&#39;(&quot;a&quot;) + True -&#39;)</span>
<span class="go">TokenInfo(type=3 (STRING), string=&#39;&quot;a&quot;&#39;, start=(1, 1), end=(1, 4), line=&#39;(&quot;a&quot;) + True -&#39;)</span>
<span class="go">TokenInfo(type=53 (OP), string=&#39;)&#39;, start=(1, 4), end=(1, 5), line=&#39;(&quot;a&quot;) + True -&#39;)</span>
<span class="go">TokenInfo(type=53 (OP), string=&#39;+&#39;, start=(1, 6), end=(1, 7), line=&#39;(&quot;a&quot;) + True -&#39;)</span>
<span class="go">TokenInfo(type=1 (NAME), string=&#39;True&#39;, start=(1, 8), end=(1, 12), line=&#39;(&quot;a&quot;) + True -&#39;)</span>
<span class="go">TokenInfo(type=53 (OP), string=&#39;-&#39;, start=(1, 13), end=(1, 14), line=&#39;(&quot;a&quot;) + True -&#39;)</span>
<span class="go">TokenInfo(type=0 (ENDMARKER), string=&#39;&#39;, start=(2, 0), end=(2, 0), line=&#39;&#39;)</span>
</pre></div>
</div>
<p>The string is split into the following tokens: <code class="docutils literal notranslate"><span class="pre">(</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;a&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">+</span></code>,
<code class="docutils literal notranslate"><span class="pre">True</span></code>, <code class="docutils literal notranslate"><span class="pre">)</span></code> (ignore the <code class="docutils literal notranslate"><span class="pre">BytesIO</span></code> bit and the <code class="docutils literal notranslate"><span class="pre">ENCODING</span></code> and
<code class="docutils literal notranslate"><span class="pre">ENDMARKER</span></code> tokens for now).</p>
<p>I chose this example to demonstrate a few things:</p>
<ul>
<li><p class="first">The <em>Tokens</em> in Python are things like parentheses, strings, operators,
keywords, and variable names.</p>
</li>
<li><p class="first">Every token is a <code class="docutils literal notranslate"><span class="pre">namedtuple</span></code> which has a <code class="docutils literal notranslate"><span class="pre">type</span></code>, which is represented
by an integer constant, and a <code class="docutils literal notranslate"><span class="pre">string</span></code>, which is the substring of the
input representing the given token. The <code class="docutils literal notranslate"><span class="pre">namedtuple</span></code> also gives line and
column information that indicates exactly where in the input string the
token was found.</p>
</li>
<li><p class="first">The input does not need to be valid Python. Our input, <code class="docutils literal notranslate"><span class="pre">(&quot;a&quot;)</span> <span class="pre">+</span> <span class="pre">True</span> <span class="pre">-</span></code> is
not valid Python, but it is, however, a potential beginning of a valid
Python string. If a valid Python expression were to be added to the end of
the input, completing the subtraction operator, such as <code class="docutils literal notranslate"><span class="pre">(&quot;a&quot;)</span> <span class="pre">+</span> <span class="pre">True</span> <span class="pre">-</span>
<span class="pre">x</span></code>, it would become valid Python. <strong>This illustrates an important aspect of
tokenize, which is that it fundamentally works on a stream of
characters.</strong> This means that tokens are output as they are seen, without
regard to what comes later (the tokenize module does do lookahead on the
input stream internally to ensure that the correct tokens are output, but
from the point of view of a user of <code class="docutils literal notranslate"><span class="pre">tokenize</span></code>, each token can be
processed as it is seen). This is why <code class="docutils literal notranslate"><span class="pre">tokenize.tokenize</span></code> produces a
generator.</p>
<p>However, it should be noted that tokenize does raise an exception on certain
incomplete Python statements. For example, if we omit the closing
parenthesis, tokenize produces all the tokens as before, but then raises
<code class="docutils literal notranslate"><span class="pre">TokenError</span></code>:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">string</span> <span class="o">=</span> <span class="s1">&#39;(&quot;a&quot; + True -&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokenize</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">readline</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">print</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> 
<span class="go">TokenInfo(type=59 (ENCODING), string=&#39;utf-8&#39;, start=(0, 0), end=(0, 0), line=&#39;&#39;)</span>
<span class="go">TokenInfo(type=53 (OP), string=&#39;(&#39;, start=(1, 0), end=(1, 1), line=&#39;(&quot;a&quot; + True -&#39;)</span>
<span class="go">TokenInfo(type=3 (STRING), string=&#39;&quot;a&quot;&#39;, start=(1, 1), end=(1, 4), line=&#39;(&quot;a&quot; + True -&#39;)</span>
<span class="go">TokenInfo(type=53 (OP), string=&#39;+&#39;, start=(1, 5), end=(1, 6), line=&#39;(&quot;a&quot; + True -&#39;)</span>
<span class="go">TokenInfo(type=1 (NAME), string=&#39;True&#39;, start=(1, 7), end=(1, 11), line=&#39;(&quot;a&quot; + True -&#39;)</span>
<span class="go">TokenInfo(type=53 (OP), string=&#39;-&#39;, start=(1, 12), end=(1, 13), line=&#39;(&quot;a&quot; + True -&#39;)</span>
<span class="gt">Traceback (most recent call last):</span>
<span class="c">...</span>
<span class="gr">tokenize.TokenError</span>: <span class="n">(&#39;EOF in multi-line statement&#39;, (2, 0))</span>
</pre></div>
</div>
<p>One of the goals of this guide is to quantify exactly when these error
conditions can occur, so that code that attempts to tokenize partial Python
code can deal with them properly.</p>
</li>
<li><p class="first">Syntactically irrelevant aspects of the input such as redundant parentheses
are maintained. The parentheses around the <code class="docutils literal notranslate"><span class="pre">&quot;a&quot;</span></code> in the input string are
completely unnecessary, but they are included as tokens anyway. This does
not apply to whitespace, however (indentation is an exception to this, as we
will see later), although the whitespace between tokens can generally be
deduced from the column information in the namedtuple.</p>
</li>
<li><p class="first">The input need not be semantically meaningful in anyway. The input string,
even if completed, can only raise a <code class="docutils literal notranslate"><span class="pre">TypeError</span></code> because <code class="docutils literal notranslate"><span class="pre">&quot;a&quot;</span> <span class="pre">+</span> <span class="pre">True</span></code> is
not allowed by Python. The tokenize module does not know or care about
objects, types, or any high-level Python constructs.</p>
</li>
<li><p class="first">Some tokens can be right next to one another in the input string. Other
tokens must be separated by a space (for instance, <code class="docutils literal notranslate"><span class="pre">foriinrange(10)</span></code> will
tokenize differently from <code class="docutils literal notranslate"><span class="pre">for</span> <span class="pre">i</span> <span class="pre">in</span> <span class="pre">range(10)</span></code>). The complete set of rules
for when spaces are required or not required to separate Python tokens is
quite complicated, especially when multiline statements with indentation are
considered (as an example, consider that <code class="docutils literal notranslate"><span class="pre">1jand2</span></code> is valid Pythonâitâs
tokenized into three tokens, <code class="docutils literal notranslate"><span class="pre">NUMBER</span></code> (<code class="docutils literal notranslate"><span class="pre">1j</span></code>), <code class="docutils literal notranslate"><span class="pre">NAME</span></code> (<code class="docutils literal notranslate"><span class="pre">and</span></code>), and
<code class="docutils literal notranslate"><span class="pre">NUMBER</span></code> (<code class="docutils literal notranslate"><span class="pre">2</span></code>)). One use-case of the <code class="docutils literal notranslate"><span class="pre">tokenize</span></code> module is to combine
tokens into valid Python using the <code class="docutils literal notranslate"><span class="pre">untokenize</span></code> function, which handles
these details automatically.</p>
</li>
<li><p class="first">All parentheses and operators are tokenized as <code class="docutils literal notranslate"><span class="pre">OP</span></code>. Both variable names
and keywords are tokenized as <code class="docutils literal notranslate"><span class="pre">NAME</span></code>. To determine the exact type of a
token often requires further inspection than simply looking at the <code class="docutils literal notranslate"><span class="pre">type</span></code>
(this guide will detail exactly how to do this).</p>
</li>
<li><p class="first">The above example does not show it, but even code that can never be valid
Python is often tokenized. For example:</p>
<div class="highlight-pycon notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">string</span> <span class="o">=</span> <span class="s1">&#39;a$b&#39;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokenize</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">string</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">readline</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">print</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
<span class="go">TokenInfo(type=59 (ENCODING), string=&#39;utf-8&#39;, start=(0, 0), end=(0, 0), line=&#39;&#39;)</span>
<span class="go">TokenInfo(type=1 (NAME), string=&#39;a&#39;, start=(1, 0), end=(1, 1), line=&#39;a$b&#39;)</span>
<span class="go">TokenInfo(type=56 (ERRORTOKEN), string=&#39;$&#39;, start=(1, 1), end=(1, 2), line=&#39;a$b&#39;)</span>
<span class="go">TokenInfo(type=1 (NAME), string=&#39;b&#39;, start=(1, 2), end=(1, 3), line=&#39;a$b&#39;)</span>
<span class="go">TokenInfo(type=0 (ENDMARKER), string=&#39;&#39;, start=(2, 0), end=(2, 0), line=&#39;&#39;)</span>
</pre></div>
</div>
<p>This can be useful for dealing with code that has minor typos that makes it
invalid. It can also be used to build modules that extend the Python
language in limited ways, but be warned that the <code class="docutils literal notranslate"><span class="pre">tokenize</span></code> module makes
no guarantees about how it tokenizes invalid Python. For example, if a
future version of Python added <code class="docutils literal notranslate"><span class="pre">$</span></code> as an operator, the above string could
tokenize completely differently. This exact thing happened, for instance,
with f-strings. In Python 3.5, <code class="docutils literal notranslate"><span class="pre">f&quot;{a}&quot;</span></code> tokenizes as two tokens, <code class="docutils literal notranslate"><span class="pre">NAME</span></code> (<code class="docutils literal notranslate"><span class="pre">f</span></code>)
and <code class="docutils literal notranslate"><span class="pre">STRING</span></code> (<code class="docutils literal notranslate"><span class="pre">&quot;{a}&quot;</span></code>). In Python 3.6, it tokenizes as one token,
<code class="docutils literal notranslate"><span class="pre">STRING</span></code> (<code class="docutils literal notranslate"><span class="pre">f&quot;{a}&quot;</span></code>).</p>
</li>
<li><p class="first">Finally, the key thing to understand about tokenization is that the tokens
are a very low level abstraction of the Python syntax. The same token may
have different meanings in different contexts. For example, in <code class="docutils literal notranslate"><span class="pre">[1]</span></code>, the
<code class="docutils literal notranslate"><span class="pre">[</span></code> token is part of a list literal, whereas <code class="docutils literal notranslate"><span class="pre">a[1]</span></code>, the <code class="docutils literal notranslate"><span class="pre">[</span></code> token is
part of a slice. If you want to manipulate higher level abstractions, you
might want to use the <code class="docutils literal notranslate"><span class="pre">ast</span></code> module instead (see the <a class="reference internal" href="alternatives.html#alternatives"><span class="std std-ref">next section</span></a>).</p>
</li>
</ul>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h3><a href="index.html">Table Of Contents</a></h3>
<p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">What is tokenization?</a></li>
<li class="toctree-l1"><a class="reference internal" href="alternatives.html"><code class="docutils literal notranslate"><span class="pre">tokenize</span></code> vs. alternatives</a></li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2018, Aaron Meurer.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 1.7.4</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.10</a>
      
      |
      <a href="_sources/intro.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    
    <a href="https://github.com/asmeurer/brown-water-python" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
  </body>
</html>